#################################################################复现源论文代码#########################################
gcc -v must be 4.9.4
1. 安装环境
conda create --name CenterNet --file conda_packagelist.txt


2. Compiling Corner Pooling Layers
cd ./models/py_utils/_cpools/
python setup.py install --user

3. Compiling NMS
cd ./../../../external
make

4. Installing MS COCO APIs
cd ./../data/coco/PythonAPI
make

5. Downloading MS COCO Data


    Download the training/validation split we use in our paper from here (originally from Faster R-CNN)
    Unzip the file and place annotations under <CenterNet dir>/data/coco
    Download the images (2014 Train, 2014 Val, 2017 Test) from here
    Create 3 directories, trainval2014, minival2014 and testdev2017, under <CenterNet dir>/data/coco/images/
    Copy the training/validation/testing images to the corresponding directories according to the annotation files

# unzip 三个文件夹

# 创建软连接

cd ./../images/
ln -s /home/ghy/coco/train2014  ./trainval2014
ln -s /home/ghy/coco/val2014 ./minival2014

cd ./../
ln -s /home/ghy/coco/annotations ./annotations

# /home/ghy/GHY/CenterNet/db/coco.py
line18 
data_dir = "./data"
6. Training and Evaluation
# 可以先下载训练好的 CenterNet-104模型,放置于下面地址
mkdir <CenterNet dir>/cache/nnet

# 利用训练好的模型进行测试
python test.py CenterNet-104 --testiter 480000 --split <split>

# 若要从头训练，注意事项我们应该修改CenterNet-104.json中的batch_size来适应我们的GPU
python train.py CenterNet-104

# 或者使用小一点的网络来训练，To train CenterNet-52:
python train.py CenterNet-52

python test.py CenterNet-52 --testiter 480000 --split <split>


### error###
loading all datasets...
using 4 threads
MSCOCO###data_dir = ./data
loading from cache file: cache/coco_trainval2014.pkl
loading annotations into memory...
Done (t=8.21s)
creating index...
index created!
MSCOCO###data_dir = ./data
loading from cache file: cache/coco_trainval2014.pkl
loading annotations into memory...
Done (t=6.74s)
creating index...
index created!
MSCOCO###data_dir = ./data
loading from cache file: cache/coco_trainval2014.pkl
loading annotations into memory...
Done (t=6.79s)
creating index...
index created!
MSCOCO###data_dir = ./data
loading from cache file: cache/coco_trainval2014.pkl
loading annotations into memory...
Done (t=9.98s)
creating index...
index created!
MSCOCO###data_dir = ./data
loading from cache file: cache/coco_minival2014.pkl
loading annotations into memory...
Done (t=3.15s)
creating index...
index created!
system config...
{'batch_size': 8,
 'cache_dir': 'cache',
 'chunk_sizes': [6, 6, 6, 6, 6, 6, 6, 6],
 'config_dir': 'config',
 'data_dir': '../data',
 'data_rng': <mtrand.RandomState object at 0x7fb32404ad38>,
 'dataset': 'MSCOCO',
 'decay_rate': 10,
 'display': 5,
 'learning_rate': 0.00025,
 'max_iter': 480000,
 'nnet_rng': <mtrand.RandomState object at 0x7fb32404ad80>,
 'opt_algo': 'adam',
 'prefetch_size': 6,
 'pretrain': None,
 'result_dir': 'results',
 'sampling_function': 'kp_detection',
 'snapshot': 5000,
 'snapshot_name': 'CenterNet-52',
 'stepsize': 450000,
 'test_split': 'testdev',
 'train_split': 'trainval',
 'val_iter': 500,
 'val_split': 'minival',
 'weight_decay': False,
 'weight_decay_rate': 1e-05,
 'weight_decay_type': 'l2'}
db config...
{'ae_threshold': 0.5,
 'border': 128,
 'categories': 80,
 'data_aug': True,
 'gaussian_bump': True,
 'gaussian_iou': 0.7,
 'gaussian_radius': -1,
 'input_size': [511, 511],
 'kp_categories': 1,
 'lighting': True,
 'max_per_image': 100,
 'merge_bbox': False,
 'nms_algorithm': 'exp_soft_nms',
 'nms_kernel': 3,
 'nms_threshold': 0.5,
 'output_sizes': [[128, 128]],
 'rand_color': True,
 'rand_crop': True,
 'rand_pushes': False,
 'rand_samples': False,
 'rand_scale_max': 1.4,
 'rand_scale_min': 0.6,
 'rand_scale_step': 0.1,
 'rand_scales': array([0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3]),
 'special_crop': False,
 'test_scales': [1],
 'top_k': 70,
 'weight_exp': 8}
len of db: 82783
start prefetching data...
shuffling indices...
start prefetching data...
start prefetching data...
shuffling indices...
shuffling indices...
start prefetching data...
shuffling indices...
start prefetching data...
shuffling indices...
building model...
module_file: models.CenterNet-52
段错误 (核心已转储)


runningtime cuda error

RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'
RuntimeError: cuda runtime error (38) : no CUDA-capable device

### 解决 ###
https://github.com/princeton-vl/CornerNet/issues/47
# 重复步骤2.

These two values can be determined according to your gpu. For example, I only have one 1080Ti graphics card, batch_size: 2, chunk_sizes: [2]. The value of batch_size is equal to the value of all chunk_sizes values added.

The default configuration file assumes that there are 10 GPUs and you only have 8 GPUs. Did you change the batch_size and chunk_sizes in config/CornerNet.json file? chunk_sizes means the number of images per GPU. If you haven't changed that, try reducing the batch size and adjust the chunk_sizes accordingly.


####################################################### 训练自己的数据集 #######################################################
1. 首先制作自己的COCO格式数据集/home/ghy/xml2json/xml_to_json数据转换脚本

2. 并修改CornerNet/db/coco.py中的数据路径

self._dataset = {
            "trainval": "trainval2014",
            "minival": "minival2014",
            "testdev": "testdev2017"
        }[self._split]
---------------------------->
self._dataset = {
            "trainval": "train2017",
            "minival": "val2017",
            "testdev": "test2017"
        }[self._split]




self._cat_ids = [
            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 
            14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 
            24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 
            37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 
            48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 
            58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 
            72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 
            82, 84, 85, 86, 87, 88, 89, 90
        ]
---------------->
self._cat_ids = [
            0
        ]	# 查看json文件中的id数
3. 需要修改类别的数量
out_dim in CornerNet.py,
categories in CornerNet.json
self._configs[“categories”] in detection.py.

4. /home/ghy/GHY/CenterNet/sample/coco.py
You can adjust max_tag_len (line 66 in sample/coco.py) according to your dataset.
https://github.com/princeton-vl/CornerNet/issues/26
max_tag_len = 128
------------------------>
max_tag_len = 500


5. python test.py CornerNet --testiter 500000 --split testing
此时测试的是images/testdev2017的测试图片，我跑了大概两个小时，结果存放在result/cornernet/500000/testing下，生成的result.json文件，如果你想通是生成检测的框框，只需要在CornerNet/test/coco.py第153行if True:
193行debug_file = os.path.join(debug_dir, “{}.jpg".format(db_ind))下加cv2.imwrite(debug_file,image)
————————————————
原文链接：https://blog.csdn.net/qq_36492210/article/details/84993195
————————————————
To draw the results on image files you need some modifications in CornerNet/test/coco.py

    make Line 153 if True:
    below Line 193 debug_file = os.path.join(debug_dir, "{}.jpg".format(db_ind))
    add cv2.imwrite(debug_file, image)

that should save images to CornerNet/results/CornerNet/500000/validation


/db/coco.py
 if self._split == "testdev":
	return None
----------------->
 注释掉即可
